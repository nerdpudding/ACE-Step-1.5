# GPU 互換性ガイド

ACE-Step 1.5 は GPU の VRAM に自動的に適応し、生成時間の制限や使用可能な LM モデルを調整します。システムは起動時に GPU メモリを検出し、最適な設定を自動構成します。

## GPU ティア構成

| VRAM | ティア | LM モード | 最大時間 | 最大バッチ | LM メモリ割当 |
|------|--------|-----------|----------|------------|---------------|
| ≤4GB | Tier 1 | 利用不可 | 3 分 | 1 | - |
| 4-6GB | Tier 2 | 利用不可 | 6 分 | 1 | - |
| 6-8GB | Tier 3 | 0.6B (オプション) | LM あり: 4 分 / LM なし: 6 分 | LM あり: 1 / LM なし: 2 | 3GB |
| 8-12GB | Tier 4 | 0.6B (オプション) | LM あり: 4 分 / LM なし: 6 分 | LM あり: 2 / LM なし: 4 | 3GB |
| 12-16GB | Tier 5 | 0.6B / 1.7B | LM あり: 4 分 / LM なし: 6 分 | LM あり: 2 / LM なし: 4 | 0.6B: 3GB, 1.7B: 8GB |
| 16-24GB | Tier 6 | 0.6B / 1.7B / 4B | 8 分 | LM あり: 4 / LM なし: 8 | 0.6B: 3GB, 1.7B: 8GB, 4B: 12GB |
| ≥24GB | 無制限 | 全モデル | 10 分 | 8 | 無制限 |

## 注意事項

- **デフォルト設定** は検出された GPU メモリに基づいて自動構成されます
- **LM モード** は Chain-of-Thought 生成とオーディオ理解に使用される言語モデルを指します
- **Flash Attention**、**CPU Offload**、**Compile**、**Quantization** は最適なパフォーマンスのためデフォルトで有効です
- 要求した時間やバッチサイズが GPU の制限を超える場合、警告が表示され、値は許容最大値に調整されます
- **制約付きデコード**: LM が初期化されると、LM の時間生成も GPU ティアの最大時間制限内に制約され、CoT 生成時のメモリ不足エラーを防ぎます
- VRAM ≤6GB の GPU では、DiT モデル用のメモリを確保するため、デフォルトで LM 初期化が無効になります
- コマンドライン引数または Gradio UI で設定を手動で上書きできます

> **コミュニティ貢献歓迎**: 上記の GPU ティア構成は一般的なハードウェアでのテストに基づいています。お使いのデバイスの実際のパフォーマンスがこれらのパラメータと異なる場合（例：より長い時間やより大きなバッチサイズを処理できる）、より徹底的なテストを行い、`acestep/gpu_config.py` の構成を最適化する PR を提出することを歓迎します。皆様の貢献がすべてのユーザーの体験向上に役立ちます！

## メモリ最適化のヒント

1. **低 VRAM (<8GB)**: 最大時間を得るため、LM 初期化なしの DiT のみモードを使用
2. **中 VRAM (8-16GB)**: 品質とメモリのバランスが最適な 0.6B LM モデルを使用
3. **高 VRAM (>16GB)**: より良いオーディオ理解と生成品質のため、より大きな LM モデル (1.7B/4B) を有効化

## デバッグモード：異なる GPU 構成のシミュレーション

テストと開発のため、`MAX_CUDA_VRAM` 環境変数を使用して異なる GPU メモリサイズをシミュレートできます：

```bash
# 4GB GPU (Tier 1) をシミュレート
MAX_CUDA_VRAM=4 uv run acestep

# 8GB GPU (Tier 4) をシミュレート
MAX_CUDA_VRAM=8 uv run acestep

# 12GB GPU (Tier 5) をシミュレート
MAX_CUDA_VRAM=12 uv run acestep

# 16GB GPU (Tier 6) をシミュレート
MAX_CUDA_VRAM=16 uv run acestep
```

用途：
- ハイエンドハードウェアで GPU ティア構成をテスト
- 各ティアの警告と制限が正しく機能することを確認
- PR を提出する前に新しい GPU 構成パラメータを開発・テスト
