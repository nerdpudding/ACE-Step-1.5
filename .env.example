# ACE-Step Docker Configuration
# Copy this file to .env and adjust for your setup:
#   cp .env.example .env
#
# ╔══════════════════════════════════════════════════════════════════╗
# ║  GPU TIER GIDS - Kies de juiste instellingen voor jouw GPU     ║
# ╠══════════════════════════════════════════════════════════════════╣
# ║  VRAM    │ LM Model           │ INIT_LLM │ Max duur │ Batch   ║
# ╠══════════╪══════════════════════╪══════════╪══════════╪═════════╣
# ║  ≤6GB    │ (geen)              │ false    │ 6 min    │ 1       ║
# ║  6-8GB   │ acestep-5Hz-lm-0.6B │ true     │ 4 min    │ 1       ║
# ║  8-12GB  │ acestep-5Hz-lm-0.6B │ true     │ 4 min    │ 2       ║
# ║  12-16GB │ acestep-5Hz-lm-1.7B │ true     │ 4 min    │ 2       ║
# ║  16-24GB │ acestep-5Hz-lm-4B   │ true     │ 8 min    │ 4       ║
# ║  ≥24GB   │ acestep-5Hz-lm-4B   │ true     │ 10 min   │ 8       ║
# ╚══════════╧══════════════════════╧══════════╧══════════╧═════════╝

# ==================== GPU ====================
# Device: auto detecteert je GPU automatisch
ACESTEP_DEVICE=auto

# ==================== Model ====================
# DiT model (muziekgeneratie) - kies op basis van gebruik:
#   acestep-v15-turbo  → snel (8 steps), zeer hoge kwaliteit (aanbevolen)
#   acestep-v15-sft    → langzamer (50 steps), makkelijker te fine-tunen
#   acestep-v15-base   → langzamer (50 steps), meeste diversiteit, beste voor LoRA training
# Andere modellen moeten eerst gedownload worden: acestep-download --model <naam>
ACESTEP_CONFIG_PATH=acestep-v15-turbo

# Language Model - kies op basis van je VRAM (zie tabel hierboven)
#   acestep-5Hz-lm-0.6B  → ~3GB VRAM (6-12GB GPU's)
#   acestep-5Hz-lm-1.7B  → ~8GB VRAM (12-16GB GPU's)
#   acestep-5Hz-lm-4B    → ~12GB VRAM (16GB+ GPU's, beste kwaliteit)
ACESTEP_LM_MODEL_PATH=acestep-5Hz-lm-1.7B

# LM backend: vllm (sneller) of pt (PyTorch native, als vllm problemen geeft)
ACESTEP_LM_BACKEND=vllm

# LLM laden? auto/true/false
#   auto  = laat GPU auto-detectie beslissen (aanbevolen)
#   true  = altijd laden (kan OOM geven bij te weinig VRAM)
#   false = niet laden (alleen DiT mode, sneller maar minder features)
#
# Zonder LLM mis je: Thinking mode, Chain-of-Thought, Sample mode, Format mode
ACESTEP_INIT_LLM=auto

# ==================== Download ====================
# Bron voor model downloads: auto, huggingface, modelscope
ACESTEP_DOWNLOAD_SOURCE=auto

# ==================== Poorten ====================
# Externe poorten op je host machine (pas aan als ze al bezet zijn)
# Gradio UI:  http://localhost:8500
# REST API:   http://localhost:8501
GRADIO_PORT=8500
API_PORT=8501

# API key voor authenticatie (optioneel)
# ACESTEP_API_KEY=sk-your-secret-key

# ==================== Meerdere GPU's (optioneel) ====================
# Als je meerdere GPU's hebt, stel hier in welke gebruikt wordt.
# Check je GPU device ID met: nvidia-smi --query-gpu=index,name --format=csv
# Bij 1 GPU hoef je dit niet aan te passen.
ACESTEP_GPU_DEVICE=0